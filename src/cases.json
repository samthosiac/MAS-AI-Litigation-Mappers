[
	{
		"name_of_algorithm_text": "Gemini",
		"class_action_list": "'No'",
		"organizations_involved": "Google, Penske Media Corporation, Artforum, Art Media, Billboard, Hollywood Reporter, Rolling Stone, Variety, Alphabet",
		"jurisdiction_filed": "D.D.C.",
		"date_action_filed": "2025-09-12",
		"current_jurisdiction": "D.D.C.",
		"jurisdiction_name": "USDC District of Columbia",
		"published_opinions_binary": 0,
		"status_disposition": "Active",
		"date_added": "2025-09-24",
		"last_update": "2025-09-24",
		"researcher": "",
		"summary_of_significance": "Given Google's recent antitrust win permitting them to keep its Chrome browser, it will be interesting to see how this case lands.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "Complaint Filed",
		"most_recent_activity_date": "2025-09-12",
		"keyword": "Penske Media Corporation v. Google LLC Owner of Rolling Stone, Variety, and Billboard sues Google over their AI overviews claiming that the overviews, which now appear at the top of Google's search results, harms their advertising, affiliate link, and subscription revenue by directing traffic away from plaintiff's sites. Given Google's recent antitrust win permitting them to keep its Chrome browser, it will be interesting to see how this case lands. PMC has allowed to google to crawl their websites in exchange for generating search traffic related to the website content. However, Plaintiff alleges that Google has required this information to also be used to train their LLMs to continue the exchange. Google then uses this information to generate AI Overviews, which in turn have lead to lower click-through rates to the original sources where the information may have originated from. Plaintiff's allege that Google exercises its monopoly power to prevent companies from charging Google for the information used to train Google's LLM or opt out altogether. On September 12th, 2025 PMC filed suit including the following claims: Reciprocal Dealing, Unlawful Monopoly Leveraging, and Unlawful Monopolization in violation of the Sherman Act, and Unjust Enrichment. Google, Penske Media Corporation, Artforum, Art Media, Billboard, Hollywood Reporter, Rolling Stone, Variety, Alphabet Gemini Advertising, Generative AI Sherman Act, Unjust Enrichment USDC District of Columbia Antitrust",
		"jurisdiction_type_text": "U.S. Federal",
		"filing_year": 2025,
		"case_id": "0cec0e8e60106c100c4f2f048b79e0af"
	},

	{
			"case_snug": "",
		"id": 396,
		"record_number": 396,
		"caption": "Samuels v. Lido DAO et al.",
		"brief_description": "An individual investor files a putative class action against a decentralized autonomous organization (DAO) and its institutional investors, asserting claims of unregistered security sales, arising from the defendants' offer and sale of LDO tokens on crypto exchanges without registration.",
		"area_of_application_list": "'Civil Rights','Investment'",
		"area_of_application_text": "Civil Rights, Investment",
		"issue_text": "Breach of Contract,Accountability, Justiciability, Misrepresentation, Notice, Personally Identifiable Information, Terms of Service, Transparency/Trade Secrecy, Unaware of Use of Algorithm",
		"issue_list": "'Accountability','Breach of Contract','Justiciability','Misrepresentation','Notice','Personally Identifiable Information','Terms of Service','Transparency/Trade Secrecy','Unaware of Use of Algorithm'",
		"cause_of_action_list": "'Breach of Contract'",
		"cause_of_action_text": "Breach of Contract",
		"issue_list_old": "'Accountability','Justiciability','Misrepresentation','Notice','Personally Identifiable Information','Terms of Service','Transparency/Trade Secrecy','Unaware of Use of Algorithm'",
			"issue_text_old": "Accountability, Justiciability, Misrepresentation, Notice, Personally Identifiable Information, Terms of Service, Transparency/Trade Secrecy, Unaware of Use of Algorithm"
		},
		{
			"name_of_algorithm_text": "Ethereum Staking Protocol; Smart Contracts",
		"class_action_list": "'Yes'",
		"organizations_involved": "Andrew Samuels; Lido DAO; Paradigm Operations LP; AH Capital Management LLC (Andreessen Horowitz); Dragonfly Digital Management LLC; Robot Ventures LP",
		"jurisdiction_filed": "N.D. Cal.",
		"date_action_filed": "2023-12-17",
		"current_jurisdiction": "N.D. Cal.",
		"published_opinions_binary": -1,
		"status_disposition": "Active",
		"date_added": "2025-12-26",
		"last_update": "2025-12-26",
		"researcher": "Aiymgul Kachyke",
		"summary_of_significance": "This case is a landmark ruling on the legal personhood of DAOs. The court rejected the argument that a DAO is merely 'autonomous software,' instead holding that it can be treated as a general partnership under state law. This creates a potential new frontier for liability where individual tokenholders and venture capital investors may be held personally liable for a DAO's actions.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "Order Granting Motion to Dismiss Conditional Counterclaims.",
		"most_recent_activity_date": "2025-04-09",
		"keyword": "Samuels v. Lido DAO et al. An individual investor files a putative class action against a decentralized autonomous organization (DAO) and its institutional investors, asserting claims of unregistered security sales, arising from the defendants' offer and sale of LDO tokens on crypto exchanges without registration. This case is a landmark ruling on the legal personhood of DAOs. The court rejected the argument that a DAO is merely 'autonomous software,' instead holding that it can be treated as a general partnership under state law. This creates a potential new frontier for liability where individual tokenholders and venture capital investors may be held personally liable for a DAO's actions. Andrew Samuels sued Lido DAO and its major investors after losing money on LDO tokens. He alleged that Lido is a for-profit general partnership that sold unregistered securities. Lido initially ignored the suit, arguing it was not a legal entity, but was forced to respond after a default motion. In November 2024, Judge Vince Chhabria ruled that Lido's operations—involving 70+ employees and a treasury—demonstrate it is an entity run by people, not just software. In April 2025, the court dismissed counterclaims that sought to treat the plaintiff himself as a partner in the DAO. Andrew Samuels; Lido DAO; Paradigm Operations LP; AH Capital Management LLC (Andreessen Horowitz); Dragonfly Digital Management LLC; Robot Ventures LP Ethereum Staking Protocol; Smart Contracts Civil Rights, Investment Breach of Contract California (federal) Accountability, Justiciability, Misrepresentation, Notice, Personally Identifiable Information, Terms of Service, Transparency/Trade Secrecy, Unaware of Use of Algorithm",
		"jurisdiction_type_text": "U.S. Federal",
		"filing_year": 2023,
		"case_id": "ce23f88d95d90e29e8214f505c6e9bbc"
	},
  
  { "case_snug": "erc-v-adams-investment-group", "id": 135, "record_number": 141, "caption": "ERC v. Adams Investment Group", "brief_description": "A management firm that administers leases and tenant applications in the District and buildings across the country has agreed in a settlement to evaluate its software and ensure none of its properties discriminate against renters who receive government housing subsidies — a practice that D.C. groups allege the company had previously engaged in.", "area_of_application_list": "'Civil Rights','Housing'", "area_of_application_text": "Civil Rights, Housing", "issue_text": "Civil Rights,Programmer Bias, Socioeconomics Bias, Use of Race", "issue_list": "'Civil Rights','Programmer Bias','Socioeconomics Bias','Use of Race'", "cause_of_action_list": "'Civil Rights'", "cause_of_action_text": "Civil Rights", "issue_list_old": "'Programmer Bias','Socioeconomics Bias','Use of Race'", "issue_text_old": "Programmer Bias, Socioeconomics Bias, Use of Race", "name_of_algorithm_list": "", "name_of_algorithm_text": "", "class_action_list": "'No'", "organizations_involved": "", "jurisdiction_filed": "D.C. Super Ct.", "date_action_filed": "2022-04-11", "current_jurisdiction": "D.C. Super Ct.", "jurisdiction_name": "District of Columbia", "published_opinions_binary": 0, "status_disposition": "Inactive", "date_added": "2024-02-26", "last_update": "2024-02-26", "researcher": "Caroline", "summary_of_significance": "The ERC is a civil rights organization that identifies and seeks to eliminate unlawful and unfair discrimination in housing, employment, and public accommodations in its home community of Greater Washington, D.C. and nationwide.\n\nDefendants’ unlawful discrimination has harmed the ERC and the communities that it serves by (i) frustrating the ERC’s mission of eliminating discrimination against members of statutorily-protected classes, and (ii) causing it to divert and redirect scarce resources to counteract Defendants’ unlawful discrimination.\n\nThe ERC has made it part of its mission to eliminate source of income discrimination since at least 2003, when the ERC began receiving complaints that Voucher holders were experiencing discriminatory barriers to their ability to secure rental housing with a Voucher.\n\nDefendants’ refusal to accept Voucher holders as renters thwarted the ERC’s mission to eliminate source of income discrimination.", "summary_facts_activity_to_date": "", "most_recent_activity": "consent order", "most_recent_activity_date": "2023-12-06", "keyword": "ERC v. Adams Investment Group A management firm that administers leases and tenant applications in the District and buildings across the country has agreed in a settlement to evaluate its software and ensure none of its properties discriminate against renters who receive government housing subsidies — a practice that D.C. groups allege the company had previously engaged in. The ERC is a civil rights organization that identifies and seeks to eliminate unlawful and unfair discrimination in housing, employment, and public accommodations in its home community of Greater Washington, D.C. and nationwide.\n\nDefendants’ unlawful discrimination has harmed the ERC and the communities that it serves by (i) frustrating the ERC’s mission of eliminating discrimination against members of statutorily-protected classes, and (ii) causing it to divert and redirect scarce resources to counteract Defendants’ unlawful discrimination.\n\nThe ERC has made it part of its mission to eliminate source of income discrimination since at least 2003, when the ERC began receiving complaints that Voucher holders were experiencing discriminatory barriers to their ability to secure rental housing with a Voucher.\n\nDefendants’ refusal to accept Voucher holders as renters thwarted the ERC’s mission to eliminate source of income discrimination. On 4/11/2022, the Equal Rights Center (ERC) filed suit against Adams Investment Group, LLC and Adams-Cathedral, LLC in DC Superior Court. The complaint is based on a civil rights testing investigation which revealed Defendants’ unlawful refusal to accept vouchers as a source of income to pay the rent at Adams View apartments in the Cleveland Park neighborhood of the District. Additionally, ERC alleges in its complaint that Defendants’ policy or practice of refusing vouchers has an adverse and disparate impact based on race because, in the District, Black renters are significantly more likely to use a voucher to pay all or a portion of the rent than white renters. The complaint alleges that Defendants’ conduct violates the DC Human Rights Act (DCHRA), which prohibits discrimination based on race and lawful source of income, and violates the DC Consumer Protection Procedures Act (DCCPPA). The lawsuit seeks declaratory, injunctive, and monetary relief.\n\nA settlement agreement between parties were made on 12/6/2023. Defendants in the case have maintained that they did not engage in discriminatory practices and, according to the settlement agreement released Tuesday, agreed not to discriminate in the future against any prospective renters on any basis prohibited by federal or local law.\n\nEntrata (one of the Defendants), which runs software that enables landlords and property managers to run more leasing processes digitally, agreed to review its practices in jurisdictions where source-of-income discrimination is prohibited — within and beyond the borders of the District — and encode in its internal operations and documents that vouchers are accepted at the properties it represents.   Civil Rights, Housing Civil Rights District of Columbia Programmer Bias, Socioeconomics Bias, Use of Race", "jurisdiction_type_text": "U.S. State", "filing_year": 2022, "case_id": "4bf8805767888c69514adcefae3b0023" },
  { "case_snug": "shanghai-character-license-administrative-co-v-ai-company", "id": 149, "record_number": 155, "caption": "Shanghai Character License Administrative Co. v. AI Company", "brief_description": "SCLA's claims infringement of the copyright in the character Ultraman by AI Company as the operator of a text-to-image generative AI service that would, when prompted with \"Ultraman\" or related expressions, produce graphic images that were substantially similar to one or more versions of the Ultraman character.", "area_of_application_list": "'Generative AI'", "area_of_application_text": "Generative AI", "issue_text": "Copyright Infringement,Copyright Infringement", "issue_list": "'Copyright Infringement'", "cause_of_action_list": "'Copyright Infringement'", "cause_of_action_text": "Copyright Infringement", "issue_list_old": "'Copyright Infringement'", "issue_text_old": "Copyright Infringement", "name_of_algorithm_list": "", "name_of_algorithm_text": "", "class_action_list": "'No'", "organizations_involved": "", "jurisdiction_filed": "Guangzhou Internet Ct.", "date_action_filed": "2024-01-05", "current_jurisdiction": "Guangzhou Internet Ct.", "jurisdiction_name": "China", "published_opinions_binary": -1, "status_disposition": "Active", "date_added": "2024-03-13", "last_update": "2024-03-13", "researcher": "Bob", "summary_of_significance": "The Guangzhou Internet Court's judgment is possibly the first ever to hold the operator of a generative AI service directly liable for copyright infringement. Infringement of copyright in characters is an area in which generative AI services are particularly at risk, and this judgment shows that. The court rejected the defendant's argument that it should not be held liable as it had actually contracted with a third-party provider which provided the generative AI service, because the Interim Measures for the Administration of Generative Artificial Intelligence Services require parties who offer such services to take certain precautions, which the defendant did not do.", "summary_facts_activity_to_date": "", "most_recent_activity": "Final judgment of Guangzhou Internet Court issued", "most_recent_activity_date": "2024-03-08", "keyword": "Shanghai Character License Administrative Co. v. AI Company SCLA's claims infringement of the copyright in the character Ultraman by AI Company as the operator of a text-to-image generative AI service that would, when prompted with \"Ultraman\" or related expressions, produce graphic images that were substantially similar to one or more versions of the Ultraman character. The Guangzhou Internet Court's judgment is possibly the first ever to hold the operator of a generative AI service directly liable for copyright infringement. Infringement of copyright in characters is an area in which generative AI services are particularly at risk, and this judgment shows that. The court rejected the defendant's argument that it should not be held liable as it had actually contracted with a third-party provider which provided the generative AI service, because the Interim Measures for the Administration of Generative Artificial Intelligence Services require parties who offer such services to take certain precautions, which the defendant did not do. Defendant AI Company offers a text-to-image generative AI service. Plaintiff Shanghai Character License Company presented evidence that when the service was prompted with \"Ultraman\" or related expressions, the AI Company's service would produce images of figures that were substantially similar to one or more versions of the Ultraman character.  The Guangzhou Internet Court rendered a judgment on February 8, 2024, holding AI Company liable for copyright infringement.   Generative AI Copyright Infringement China Copyright Infringement", "jurisdiction_type_text": "International", "filing_year": 2024, "case_id": "7b3214fcd484016823bd21e6b4e65a48" },
  { "case_snug": "mehier-taamneh-v-twitter-inc", "id": 161, "record_number": 167, "caption": "Mehier Taamneh v. Twitter, Inc.", "brief_description": "Plaintiffs sued Google, Twitter, and Facebook in the District Court for the Northern District of California. They claimed, among other things, that the social media companies were directly liable under the Antiterrorism Act of 200113 (ATA) and indirectly liable under the Justice Against Sponsors of Terrorism Act14 (JASTA).\n\nThe United States District Court for the Northern District of California dismissed plaintiffs' complaint for failure to state a claim. The U.S. Court of Appeals for the Ninth Circuit reversed the District Court's decision.", "area_of_application_list": "'Social Media','Terrorism'", "area_of_application_text": "Social Media, Terrorism", "issue_text": "Antiterrorism Act,Accountability", "issue_list": "'Accountability','Antiterrorism Act'", "cause_of_action_list": "'Antiterrorism Act'", "cause_of_action_text": "Antiterrorism Act", "issue_list_old": "'Accountability'", "issue_text_old": "Accountability", "name_of_algorithm_list": "", "name_of_algorithm_text": "", "class_action_list": "'No'", "organizations_involved": "", "jurisdiction_filed": "N.D. Cal.", "date_action_filed": "2018-11-13", "current_jurisdiction": "N.D. Cal.", "jurisdiction_name": "California (federal)", "published_opinions_binary": -1, "status_disposition": "Inactive", "date_added": "2024-03-29", "last_update": "2024-07-28", "researcher": "Caroline", "summary_of_significance": "", "summary_facts_activity_to_date": "", "most_recent_activity": "Opinion", "most_recent_activity_date": "2021-06-22", "keyword": "Mehier Taamneh v. Twitter, Inc. Plaintiffs sued Google, Twitter, and Facebook in the District Court for the Northern District of California. They claimed, among other things, that the social media companies were directly liable under the Antiterrorism Act of 200113 (ATA) and indirectly liable under the Justice Against Sponsors of Terrorism Act14 (JASTA).\n\nThe United States District Court for the Northern District of California dismissed plaintiffs' complaint for failure to state a claim. The U.S. Court of Appeals for the Ninth Circuit reversed the District Court's decision.  In 2017, allegedly at the direction of ISIS, a man shot and killed 39 people at a nightclub in Istanbul, Turkey. Relatives of one of the victims sued Twitter, Google, and Facebook under the ATA, alleging they aided and abetted ISIS. Plaintiffs alleged that Defendants were a critical part of ISIS’s growth, allowing it to recruit members, issue terrorist threats, and spread propaganda. But Plaintiffs did not allege that ISIS had used Defendants’ services in planning or executing this particular attack, or that the gunman had used their services at all. The complaint acknowledged that Defendants had policies prohibiting the use of their platforms for promoting terrorism but alleged that Defendants generally only reviewed ISIS’s use of its services in response to third-party complaints and did not proactively remove tweets and accounts. \n\nThe district court granted the defen­dants’ motion to dismiss for failure to state a claim. First, Judge Chen found that the plaintiffs’ direct liability claim failed to adequately allege proximate causation. He explained that the ATA’s “by reason of” language required a showing of “some direct relationship” between the plaintiffs’ injuries and the defendants’ acts. Conclusory allegations that ISIS’s use of social media radicalized Masharipov fell short of the requirement. Turning to indirect liability, Judge Chen concluded that the complaint failed to show the defendants were generally aware of their role in ISIS’s terrorist activities or that they offered substantial assistance. The plaintiffs appealed the dismissal of their JASTA claim.\n\nThe Ninth Circuit reversed. Writing for the panel, Judge Christen concluded that the plaintiffs’ complaint satisfied the tripartite test for aiding and abetting liability under JASTA. She reviewed the three elements outlined in Halberstam v. Welch, which JASTA specified as “the proper legal framework”: (1) the aided principal must “perform a wrongful act” causing injury, (2) the defendant must be “generally aware” of his or her role in the illegal activity, and (3) the defendant must “knowingly and substantially assist the principal violation.” The parties did not dispute that the first element was satisfied. Next, persistent media coverage of and governmental pressure concerning ISIS’s social media use established the defendants’ general awareness. The plaintiffs also satisfied the knowing-assistance prong of the third element by alleging that the defendants “refused to take meaningful steps” to prevent ISIS from promoting and facilitating terrorist activities by using their social media platforms. As for the substantial-assistance prong, the court went through the six factors outlined in Halberstam to conclude that the plaintiffs cleared this requirement as well by alleging “that defendants provided services that were central to ISIS’s growth and expansion . . . over many years.”\n\nThe case is later appealed to the Supreme Court and tracked in https://c7amf338.caspio.com/dp/c2bb9000b90232f807354b6889ce.   Social Media, Terrorism Antiterrorism Act California (federal) Accountability", "jurisdiction_type_text": "U.S. Federal", "filing_year": 2018, "case_id": "145eaad10a814a2e849f64a8932f8a0c" },
	{"case_snug": "dubus-v-nvidia-corporation", "id": 182, "record_number": 189, "caption": "Dubus v. NVIDIA Corporation", "brief_description": "Two authors file proposed class action lawsuit against NVIDIA alleging copyright infringement for use of works to train large language models (LLMs).", "area_of_application_list": "'Generative AI','Intellectual Property'", "area_of_application_text": "Generative AI, Intellectual Property", "issue_text": "Copyright Infringement,Copyright Infringement", "issue_list": "'Copyright Infringement'", "cause_of_action_list": "'Copyright Infringement'", "cause_of_action_text": "Copyright Infringement", "issue_list_old": "'Copyright Infringement'", "issue_text_old": "Copyright Infringement", "name_of_algorithm_list": "", "name_of_algorithm_text": "NeMo Megatron-GPT", "class_action_list": "", "organizations_involved": "NVIDIA", "jurisdiction_filed": "N.D. Cal.", "date_action_filed": "2024-05-02", "current_jurisdiction": "N.D. Cal.", "jurisdiction_name": "California (federal)", "published_opinions_binary": 0, "status_disposition": "Active", "date_added": "2024-06-12", "last_update": "2024-06-12", "researcher": "Andrew Ware", "summary_of_significance": "Website that hosts NeMo Megatron models provides a model card that indicates each of the models were trained on a dataset that was prepared by a third party. This dataset, 'The Pile,' was prepared by research organization EleutherAI; one of the components of the dataset is a collection of books. This unlicensed copyrighted material makes up approximately 12% of the dataset.", "summary_facts_activity_to_date": "", "most_recent_activity": "", "most_recent_activity_date": "", "keyword": "Dubus v. NVIDIA Corporation Two authors file proposed class action lawsuit against NVIDIA alleging copyright infringement for use of works to train large language models (LLMs). Website that hosts NeMo Megatron models provides a model card that indicates each of the models were trained on a dataset that was prepared by a third party. This dataset, 'The Pile,' was prepared by research organization EleutherAI; one of the components of the dataset is a collection of books. This unlicensed copyrighted material makes up approximately 12% of the dataset. Plaintiffs are two authors who hold copyrights to books that were included in the dataset used to train NVIDIA's large language models, known as NeMo Megatron-GPT. Plaintiffs and proposed class members did not authorize the use of their copyrighted material. Plaintiffs bring copyright infringement lawsuit according to 17 U.S.C. § 501. NVIDIA admitted to training its models on a copy of 'The Pile' dataset, which included the infringed works. Ordered related to Nazemian v. NVIDIA Corporation (24-cv-01454) on 5/29/2024. NVIDIA NeMo Megatron-GPT Generative AI, Intellectual Property Copyright Infringement California (federal) Copyright Infringement", "jurisdiction_type_text": "U.S. Federal", "filing_year": 2024, "case_id": "fc4ae480c38a2023aba5b9a8811ef053"},
	{"case_snug": "the-center-for-investigative-reporting-inc-v-openai", "id": 248, "record_number": 248, "caption": "The Center for Investigative Reporting, Inc. v. OpenAI", "brief_description": "Nonprofit newsroom sues generative AI developers OpenAI and Microsoft, alleging direct and contributory copyright infringement and removal of copyright management information.", "area_of_application_list": "'Generative AI'", "area_of_application_text": "Generative AI", "issue_text": "'opyright Infringement,17 U.S.C. 1202 Removal of Copyright Management Information,Copyright Infringement, Fair Use", "issue_list": "'17 U.S.C. 1202 Removal of Copyright Management Information','Copyright Infringement','Fair Use','''opyright Infringement'", "cause_of_action_list": "'17 U.S.C. 1202 Removal of Copyright Management Information','Copyright Infringement'", "cause_of_action_text": "'opyright Infringement,17 U.S.C. 1202 Removal of Copyright Management Information", "issue_list_old": "'Copyright Infringement','Fair Use'", "issue_text_old": "Copyright Infringement, Fair Use", "name_of_algorithm_list": "'ChatGPT'", "name_of_algorithm_text": "ChatGPT", "class_action_list": "'No'", "organizations_involved": "OpenAI, Microsoft", "jurisdiction_filed": "S.D.N.Y.", "date_action_filed": "2024-06-27", "current_jurisdiction": "S.D.N.Y.", "jurisdiction_name": "New York (federal)", "published_opinions_binary": 0, "status_disposition": "Active", "date_added": "2024-08-05", "last_update": "2025-09-04", "researcher": "Bob", "summary_of_significance": "", "summary_facts_activity_to_date": "", "most_recent_activity": "Order on Motion to Appear Pro Hac Vice", "most_recent_activity_date": "2025-07-24", "keyword": "The Center for Investigative Reporting, Inc. v. OpenAI Nonprofit newsroom sues generative AI developers OpenAI and Microsoft, alleging direct and contributory copyright infringement and removal of copyright management information.  <p style=\"line-height: 2.0;\">Note: This case has been consolidated into <a href=\"https://blogs.gwu.edu/law-eti/ai-litigation-database/case-detail-page/?pid=309\" target=\"_blank\">In re OpenAI, Inc. Copyright Infringement Litigation</a>, pending in the Southern District of New York.</p>\n\nComplaint filed June 27, 2024 OpenAI, Microsoft ChatGPT Generative AI 'opyright Infringement,17 U.S.C. 1202 Removal of Copyright Management Information New York (federal) Copyright Infringement, Fair Use", "jurisdiction_type_text": "U.S. Federal", "filing_year": 2024, "case_id": "ddc7795cb191382cbde70f7b65d3099a"}
	,
		{
		"case_snug": "connecticut-fair-housing-center-et-al-v-corelogic-rental-property-solutions",
		"id": 104,
		"record_number": 109,
		"caption": "Connecticut Fair Housing Center, et al. v. CoreLogic Rental Property Solutions",
		"brief_description": "The Connecticut Fair Housing Center and the National Housing Law Project have filed a new lawsuit in the U.S. District Court for the District of Connecticut contending that CoreLogic Rental Property Solutions (“CoreLogic”) violates the Fair Housing Act by disproportionately disqualifying African-American and Latino applicants from securing housing based on discriminatory use of criminal records as rental criteria.",
		"area_of_application_list": "'Civil Rights','Housing'",
		"area_of_application_text": "Civil Rights, Housing",
		"issue_text": "Fair Housing Act, Unfair and Deceptive Trade Practices,Lack of Remedy, Socioeconomics Bias, Use of Race",
		"issue_list": "'Fair Housing Act','Lack of Remedy','Socioeconomics Bias','Unfair and Deceptive Trade Practices','Use of Race'",
		"cause_of_action_list": "'Fair Housing Act','Unfair and Deceptive Trade Practices'",
		"cause_of_action_text": "Fair Housing Act, Unfair and Deceptive Trade Practices",
		"issue_list_old": "'Lack of Remedy','Socioeconomics Bias','Use of Race'",
		"issue_text_old": "Lack of Remedy, Socioeconomics Bias, Use of Race",
		"name_of_algorithm_list": "",
		"name_of_algorithm_text": "",
		"class_action_list": "",
		"organizations_involved": "CoreLogic Rental Property Solutions",
		"jurisdiction_filed": "D. Conn.",
		"date_action_filed": "2018-04-24",
		"current_jurisdiction": "D. Conn.",
		"jurisdiction_name": "Connecticut (federal)",
		"published_opinions_binary": -1,
		"status_disposition": "Active",
		"date_added": "2024-01-10",
		"last_update": "2024-01-10",
		"researcher": "Caroline",
		"summary_of_significance": "The Connecticut Fair Housing Center and the National Housing Law Project have filed a new lawsuit in the U.S. District Court for the District of Connecticut contending that CoreLogic Rental Property Solutions (“CoreLogic”) violates the Fair Housing Act by disproportionately disqualifying African-American and Latino applicants from securing housing based on discriminatory use of criminal records as rental criteria.\n\nThe lawsuit asserts that CoreLogic’s tenant screening tool denied a Connecticut mother’s request to move her disabled son into her apartment based on a record of a dismissed shoplifting arrest from 2014.  Although rental decisions have traditionally been made by housing providers, today many landlords contract with third-party tenant-screeners to make admission decisions for them.  This litigation seeks to ensure that CoreLogic and all tenant-screening companies who functionally make rental decisions on behalf of landlords make those decisions in accordance with fair housing requirements.\n\nThis litigation seeks to ensure that CoreLogic and all tenant-screening companies follow fair housing requirements when they functionally make rental decisions on behalf of landlords, which adversely affected both Ms. Arroyo and the Connecticut Fair Housing Center and its mission of ensuring fair housing for the people of Connecticut.\n\nThe U.S. Department of Housing & Urban Development observed in 2016 that excluding rental applicants because of their criminal records disproportionately harms Latinos and African Americans, who are significantly more likely than whites to be arrested or convicted.  Studies show such disparities are linked to differential enforcement rather than to differences in likelihood of engaging in criminal activity.  HUD advised that to avoid discriminating, an “individualized review” should be conducted considering the nature of the offense, how long ago it occurred, intervening changed circumstances, and other relevant factors to avoid denying housing to an applicant who does not pose a genuine and ongoing threat to persons or property.  Further, HUD’s guidance specifically advises landlords not to consider arrests that did not result in a conviction in making their evaluations.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "Plaintiffs filed an appeal with the Second Circuit",
		"most_recent_activity_date": "2023-08-04",
		"keyword": "Connecticut Fair Housing Center, et al. v. CoreLogic Rental Property Solutions The Connecticut Fair Housing Center and the National Housing Law Project have filed a new lawsuit in the U.S. District Court for the District of Connecticut contending that CoreLogic Rental Property Solutions (“CoreLogic”) violates the Fair Housing Act by disproportionately disqualifying African-American and Latino applicants from securing housing based on discriminatory use of criminal records as rental criteria. The Connecticut Fair Housing Center and the National Housing Law Project have filed a new lawsuit in the U.S. District Court for the District of Connecticut contending that CoreLogic Rental Property Solutions (“CoreLogic”) violates the Fair Housing Act by disproportionately disqualifying African-American and Latino applicants from securing housing based on discriminatory use of criminal records as rental criteria.\n\nThe lawsuit asserts that CoreLogic’s tenant screening tool denied a Connecticut mother’s request to move her disabled son into her apartment based on a record of a dismissed shoplifting arrest from 2014.  Although rental decisions have traditionally been made by housing providers, today many landlords contract with third-party tenant-screeners to make admission decisions for them.  This litigation seeks to ensure that CoreLogic and all tenant-screening companies who functionally make rental decisions on behalf of landlords make those decisions in accordance with fair housing requirements.\n\nThis litigation seeks to ensure that CoreLogic and all tenant-screening companies follow fair housing requirements when they functionally make rental decisions on behalf of landlords, which adversely affected both Ms. Arroyo and the Connecticut Fair Housing Center and its mission of ensuring fair housing for the people of Connecticut.\n\nThe U.S. Department of Housing & Urban Development observed in 2016 that excluding rental applicants because of their criminal records disproportionately harms Latinos and African Americans, who are significantly more likely than whites to be arrested or convicted.  Studies show such disparities are linked to differential enforcement rather than to differences in likelihood of engaging in criminal activity.  HUD advised that to avoid discriminating, an “individualized review” should be conducted considering the nature of the offense, how long ago it occurred, intervening changed circumstances, and other relevant factors to avoid denying housing to an applicant who does not pose a genuine and ongoing threat to persons or property.  Further, HUD’s guidance specifically advises landlords not to consider arrests that did not result in a conviction in making their evaluations. Cohen Milstein is partnering with Connecticut Fair Housing Center and the National Housing Law Project in the representation of Carmen Arroyo, as well as the Connecticut Fair Housing Center itself, against CoreLogic Rental Property Solutions (“CoreLogic”), a third-party tenant-screening company, for violating the Fair Housing Act by discriminatory use of criminal records as rental criteria.\n\nOriginally filed on April 24, 2018 with the U.S. District Court, District of Connecticut, the lawsuit asserts that CoreLogic’s automated tenant screening software tool (“CrimSAFE”) denied Carmen Arroyo’s request to move her disabled son into her rental apartment based on a record of a dismissed shoplifting arrest from 2014, before he became disabled.\n\nOn August 7, 2020, the U.S. District Court, District of Connecticut denied CoreLogic’s motion for summary judgment regarding Plaintiffs’ standing and Plaintiffs’ claims of race and national origin discrimination in violation of the Fair Housing Act. \n\nOn July 20, 2023, after a bench trial that was started on March 14, 2022 and subsequently postponed by the court to re-start on October 24, 2022 and ultimately concluded on November 4, 2022, the court ruled that CoreLogic is not subject to the FHA. Plaintiffs filed an appeal with the United States Court of Appeals for the Second Circuit on August 4, 2023.\n\nOn November 24, 2023, the Department of Justice filed an amicus brief with the Second Circuit, asking the appellate court to remand the case with instructions for reconsidering whether CoreLogic’s actions create liability under the Fair Housing Act. CoreLogic Rental Property Solutions  Civil Rights, Housing Fair Housing Act, Unfair and Deceptive Trade Practices Connecticut (federal) Lack of Remedy, Socioeconomics Bias, Use of Race",
		"jurisdiction_type_text": "U.S. Federal",
		"filing_year": 2018,
		"case_id": "d81a5c48c38474bba1a2a90cc7debb16"
	},
	{
		"case_snug": "oliver-v-city-of-detroit",
		"id": 120,
		"record_number": 125,
		"caption": "Oliver v. City of Detroit",
		"brief_description": "Individual sues city for false arrest based on faulty facial recognitiion system. (dismissed in August 2024, presumably with settlement)",
		"area_of_application_list": "'Criminal Justice','Detention and Release','Facial Recognition'",
		"area_of_application_text": "Criminal Justice, Detention and Release, Facial Recognition",
		"issue_text": "42 USC 1983, Due Process, Equal Protection, Fourth Amendment, Intentional Torts, Negligence, Procedural Due Process,Facial Recognition, Law Enforcement, Socioeconomics Bias, Unreliability",
		"issue_list": "'42 USC 1983','Due Process','Equal Protection','Facial Recognition','Law Enforcement','Negligence','Socioeconomics Bias','Fourth Amendment','Intentional Torts','Procedural Due Process','Unreliability'",
		"cause_of_action_list": "'42 USC 1983','Due Process','Equal Protection','Fourth Amendment','Intentional Torts','Negligence','Procedural Due Process'",
		"cause_of_action_text": "42 USC 1983, Due Process, Equal Protection, Fourth Amendment, Intentional Torts, Negligence, Procedural Due Process",
		"issue_list_old": "'Facial Recognition','Law Enforcement','Socioeconomics Bias','Unreliability'",
		"issue_text_old": "Facial Recognition, Law Enforcement, Socioeconomics Bias, Unreliability",
		"name_of_algorithm_list": "",
		"name_of_algorithm_text": "",
		"class_action_list": "'No'",
		"organizations_involved": "",
		"jurisdiction_filed": "Mich. Wayne County Cir. Ct.",
		"date_action_filed": "2020-09-04",
		"current_jurisdiction": "E.D. Mich.",
		"jurisdiction_name": "Michigan (federal)",
		"published_opinions_binary": 0,
		"status_disposition": "Inactive",
		"date_added": "2024-02-07",
		"last_update": "2025-01-07",
		"researcher": "Caroline, Bob",
		"summary_of_significance": "Oliver is the second Detroiter to come forward with a story of a wrongful arrest due to the technology. And as protests around police misconduct swell across the country, Detroit activists have zeroed in specifically on DPD’s 2017 purchase of facial recognition technology from South Carolina vendor DataWorks Plus. They suggest Oliver and Robert Williams, who was wrongly accused of stealing watches from Shinola due to a facial recognition misidentification, are just the tip of the iceberg.\n\nDPD maintains that the Oliver misidentification — like the Williams misidentification — was the product of questionable detective work (both relied solely on facial recognition technology and photo line-ups) and is not indicative of systemic problems with the technology.\n\nThis incident underscores a bigger issue: mounting tension around Detroit Police Departments' use of facial recognition software.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "Stipulated order of dismissal",
		"most_recent_activity_date": "2024-08-22",
		"keyword": "Oliver v. City of Detroit Individual sues city for false arrest based on faulty facial recognitiion system. (dismissed in August 2024, presumably with settlement) Oliver is the second Detroiter to come forward with a story of a wrongful arrest due to the technology. And as protests around police misconduct swell across the country, Detroit activists have zeroed in specifically on DPD’s 2017 purchase of facial recognition technology from South Carolina vendor DataWorks Plus. They suggest Oliver and Robert Williams, who was wrongly accused of stealing watches from Shinola due to a facial recognition misidentification, are just the tip of the iceberg.\n\nDPD maintains that the Oliver misidentification — like the Williams misidentification — was the product of questionable detective work (both relied solely on facial recognition technology and photo line-ups) and is not indicative of systemic problems with the technology.\n\nThis incident underscores a bigger issue: mounting tension around Detroit Police Departments' use of facial recognition software.\n\n In September, Oliver filed a lawsuit in the Wayne County Circuit Court against the city of Detroit for at least $12 million. The lawsuit accuses Detroit Police of using \"failed facial recognition technology knowing the science of facial recognition has a substantial error rate among black and brown persons of ethnicity which would lead to the wrongful arrest and incarceration of persons in that ethnic demographic.\"\n\nThe plaintiff sued the City of Detroit (“COD”) and an individual COD police officer under 42 U.S.C. § 1983, equal protection under the 14th Amendment. He alleged that Defendant COD allowed others to engage in a pattern of racial discrimination of plaintiff and other African-American citizens in violation of the equal protection guaranteed by Elliott-Larsen Act. He also sued the police officer for negligence and intentional infliction of emotional distress.\n\nThe parties filed a stipulated order of dismissal, which the court accepted on August 22, 2024.  This was presumably pursuant to a settlement agrement, which however was not attached to the dismissal order.  The case was dismissed two months after the settlement in Williams v. City of Detroit (see that entry in this database), in which the City of Detroit agreed to major policy changes in its use of facial recognition software.   Criminal Justice, Detention and Release, Facial Recognition 42 USC 1983, Due Process, Equal Protection, Fourth Amendment, Intentional Torts, Negligence, Procedural Due Process Michigan (federal) Facial Recognition, Law Enforcement, Socioeconomics Bias, Unreliability",
		"jurisdiction_type_text": "U.S. Federal",
		"filing_year": 2020,
		"case_id": "9f93e0c6fc508f0fca404ddb0124a2b5"
	},
	{
		"case_snug": "open-communities-v-harbor-group-management-co-llc",
		"id": 134,
		"record_number": 140,
		"caption": "Open Communities v. Harbor Group Management Co., LLC",
		"brief_description": "Open Communities, an Evanston-based nonprofit advocating for fair housing, has filed a federal lawsuit against nationwide property management company Harbor Group Management. The lawsuit alleges the company used artificial intelligence tools to reject prospective renters who use housing choice vouchers.",
		"area_of_application_list": "'Civil Rights','Housing'",
		"area_of_application_text": "Civil Rights, Housing",
		"issue_text": "Fair Housing Act,Advertising DIscrimination, Misuse of AI, Programmer Bias, Socioeconomics Bias, Use of Race",
		"issue_list": "'Advertising Discrimination','Fair Housing Act','Misuse of AI','Programmer Bias','Socioeconomics Bias','Use of Race'",
		"cause_of_action_list": "'Fair Housing Act'",
		"cause_of_action_text": "Fair Housing Act",
		"issue_list_old": "'Advertising DIscrimination','Misuse of AI','Programmer Bias','Socioeconomics Bias','Use of Race'",
		"issue_text_old": "Advertising DIscrimination, Misuse of AI, Programmer Bias, Socioeconomics Bias, Use of Race",
		"name_of_algorithm_list": "",
		"name_of_algorithm_text": "",
		"class_action_list": "'No'",
		"organizations_involved": "",
		"jurisdiction_filed": "N.D. Ill.",
		"date_action_filed": "2023-09-25",
		"current_jurisdiction": "N.D. Ill.",
		"jurisdiction_name": "Illinois (federal)",
		"published_opinions_binary": 0,
		"status_disposition": "Inactive",
		"date_added": "2024-02-23",
		"last_update": "2024-02-23",
		"researcher": "Caroline",
		"summary_of_significance": "The lawsuit is the result of a more than six-month investigation conducted by Open Communities. \n\nThe investigation began when plaintiff Elizabeth Richardson contacted Open Communities, alleging that Harbor Group Management had discriminated against her by rejecting her application to rent at Northgate Crossing Apartments in northwest Chicago suburb Wheeling. \n\nRichardson, who is Black, uses the Housing Choice Voucher program, a federal program that issues vouchers to income-qualified Americans to cover part of their housing costs. Recipients can use the vouchers to find housing anywhere they choose — the program is not limited to designated affordable housing units. According to a Wednesday press release from Open Communities, 78% of Housing Choice Voucher recipients in Illinois are Black.\n\nThe investigation found that Harbor Group’s use of AI tools at its apartment complexes across the country consistently led to discriminatory outcomes.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "The Court grants the parties' motion for entry of consent decree",
		"most_recent_activity_date": "2024-01-23",
		"keyword": "Open Communities v. Harbor Group Management Co., LLC Open Communities, an Evanston-based nonprofit advocating for fair housing, has filed a federal lawsuit against nationwide property management company Harbor Group Management. The lawsuit alleges the company used artificial intelligence tools to reject prospective renters who use housing choice vouchers. The lawsuit is the result of a more than six-month investigation conducted by Open Communities. \n\nThe investigation began when plaintiff Elizabeth Richardson contacted Open Communities, alleging that Harbor Group Management had discriminated against her by rejecting her application to rent at Northgate Crossing Apartments in northwest Chicago suburb Wheeling. \n\nRichardson, who is Black, uses the Housing Choice Voucher program, a federal program that issues vouchers to income-qualified Americans to cover part of their housing costs. Recipients can use the vouchers to find housing anywhere they choose — the program is not limited to designated affordable housing units. According to a Wednesday press release from Open Communities, 78% of Housing Choice Voucher recipients in Illinois are Black.\n\nThe investigation found that Harbor Group’s use of AI tools at its apartment complexes across the country consistently led to discriminatory outcomes. The lawsuit alleges that the defendants “intentionally employed PERQ Artificial Intelligence automated systems to communicate a blanket ‘no Housing Choice Voucher/No Section 8 Policy’ policy to reject Internet rental applications from individuals including Richardson, who receive housing assistance payments.\n\nThe lawsuit was filed in the United States District Court for the Northern District of Illinois, and seeks “damages and injunctive relief” against the defendants.\n\nThough the defendants’ practices did not explicitly target Black applicants, Open Communities argued in the Wednesday release that the case constitutes racial discrimination, given the majority of housing choice voucher recipients are Black. \n\nAccording to a two-year consent decree approved on 1/23/2024 by U.S. District Judge Sara L. Ellis, Harbor Group International LLC agreed to several changes to end the housing discrimination claims.\n\nThe companies also signed off on a confidential settlement agreement, but denied the suit's allegations.\n\nAs part of the consent decree, Harbor Group agreed not to reject housing applicants due to their income sources. The company will also provide Open Communities with a semi-annual report about its housing applicants who use vouchers and the reasons behind any denials.   Civil Rights, Housing Fair Housing Act Illinois (federal) Advertising DIscrimination, Misuse of AI, Programmer Bias, Socioeconomics Bias, Use of Race",
		"jurisdiction_type_text": "U.S. Federal",
		"filing_year": 2023,
		"case_id": "b2d3a6692e1f26299c7d36cccc4b5143"
	},
	{
		"case_snug": "elon-musk-v-samuel-altman-et-al",
		"id": 145,
		"record_number": 151,
		"caption": "Elon Musk v. Samuel Altman et al",
		"brief_description": "Elon Musk filed a lawsuit against OpenAI and its CEO Sam Altman, alleging they have abandoned the company's founding agreement to pursue AI research for the good of humanity rather than profit.",
		"area_of_application_list": "'Generative AI'",
		"area_of_application_text": "Generative AI",
		"issue_text": "Breach of Contract, Fiduciary Duty, Unfair Competition,Misuse of AI",
		"issue_list": "'Breach of Contract','Misuse of AI','Fiduciary Duty','Unfair Competition'",
		"cause_of_action_list": "'Breach of Contract','Fiduciary Duty','Unfair Competition'",
		"cause_of_action_text": "Breach of Contract, Fiduciary Duty, Unfair Competition",
		"issue_list_old": "'Misuse of AI'",
		"issue_text_old": "Misuse of AI",
		"name_of_algorithm_list": "",
		"name_of_algorithm_text": "",
		"class_action_list": "'No'",
		"organizations_involved": "",
		"jurisdiction_filed": "Cal. Super Ct.",
		"date_action_filed": "2024-02-29",
		"current_jurisdiction": "Cal. Super Ct.",
		"jurisdiction_name": "California",
		"published_opinions_binary": 0,
		"status_disposition": "Active",
		"date_added": "2024-03-04",
		"last_update": "2024-03-04",
		"researcher": "Caroline",
		"summary_of_significance": "The case marks an escalation in the one of the highest-profile clashes in the emerging field of AI, pitting two of its most prominent players against each other. It will have implications not just for OpenAI, which is seeking to raise funds at a valuation of $100 billion or more, but also for Microsoft, which has invested about $13 billion in OpenAI.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "SUMMONS ON COMPLAINT",
		"most_recent_activity_date": "2024-03-01",
		"keyword": "Elon Musk v. Samuel Altman et al Elon Musk filed a lawsuit against OpenAI and its CEO Sam Altman, alleging they have abandoned the company's founding agreement to pursue AI research for the good of humanity rather than profit. The case marks an escalation in the one of the highest-profile clashes in the emerging field of AI, pitting two of its most prominent players against each other. It will have implications not just for OpenAI, which is seeking to raise funds at a valuation of $100 billion or more, but also for Microsoft, which has invested about $13 billion in OpenAI. Elon Musk is suing OpenAI and its CEO Sam Altman over what he says is a betrayal of the ChatGPT maker’s founding aims of benefiting humanity rather than pursuing profits.\n\nIn a lawsuit filed at San Francisco Superior Court, billionaire Musk said that when he bankrolled OpenAI’s creation, he secured an agreement with Altman and Greg Brockman, the president, to keep the AI company as a nonprofit that would develop technology for the benefit of the public.\n\nUnder its founding agreement, OpenAI would also make its code open to the public instead of walling it off for any private company’s gains, the lawsuit says.\n\nHowever, by embracing a close relationship with Microsoft, OpenAI and its top executives have set that pact “aflame” and are “perverting” the company’s mission, Musk alleges in the lawsuit.\n\nOpenAI has a unique corporate structure. It is a nonprofit charged with safeguarding humanity against artificial general intelligence, or AGI, a hypothetical AI system that can surpass humans at most tasks. But in late 2019, after Musk left the company’s board, it also established a for-profit arm with a less altruistic focus. (The profits of OpenAI LP are technically capped; investors can get back 100 times their investment, while any amount beyond that limit goes back to the nonprofit.) The explosive popularity of ChatGPT and demand for the underlying GPT-4 AI model has made that side of the company worth a reported $80 billion—and drawn the ire of Musk.\n\nThe lawsuit describes how OpenAI’s structure has become “increasingly complex” in recent years. It also takes aim at OpenAI’s relationship with Microsoft, which has invested around $13 billion into the AI company’s for-profit business in an alliance that has attracted scrutiny from regulators in the US, the EU, and the UK. \n\nThe lawsuit alleges that the internal design of GPT-4, the company’s latest model, remains secret because Microsoft and OpenAI stand to make a fortune by selling access to the AI model to the public. \"GPT-4 is hence the opposite of 'Open AI',\" the filing reads.   Generative AI Breach of Contract, Fiduciary Duty, Unfair Competition California Misuse of AI",
		"jurisdiction_type_text": "U.S. State",
		"filing_year": 2024,
		"case_id": "15a14240662f7bbe49c16ac2ccf9ec24"
	},
	{
		"record_number": 499,
		"caption": "International Council for Veterinary Assessment v. Anivive Lifesciences Inc.",
		"brief_description": "The International Council for Veterinary Assessment sues Anivive Lifesciences Inc., asserting claims of copyright infringement and breach of contract arising from the defendants' alleged inputting of copyrighted veterinary licensing exam questions into AI chatbots to test the AI's performance.",
		"area_of_application_list": "'E-Learning','Generative AI','Intellectual Property','Licensing Agreement'",
		"area_of_application_text": "E-Learning, Generative AI, Intellectual Property, Licensing Agreement",
		"issue_text": "Breach of Contract, Copyright Infringement,Misuse of AI, Terms of Service, Copyright Infringement, Fair Use",
		"issue_list": "'Breach of Contract','Copyright Infringement','Fair Use','Misuse of AI','Terms of Service'",
		"cause_of_action_list": "'Breach of Contract','Copyright Infringement'",
		"cause_of_action_text": "Breach of Contract, Copyright Infringement",
		"issue_list_old": "'Misuse of AI','Terms of Service','Copyright Infringement','Fair Use'",
		"issue_text_old": "Misuse of AI, Terms of Service, Copyright Infringement, Fair Use",
		"name_of_algorithm_list": "",
		"name_of_algorithm_text": "AI Chatbots; Large Language Models",
		"class_action_list": "'No'",
		"organizations_involved": "International Council for Veterinary Assessment; Anivive Lifesciences Inc.; David Bruyette; Cody Arbuckle; Dylan Balsz; Dorsey and Whitney LLP; Latham and Watkins LLP",
		"jurisdiction_filed": "C.D. Cal.",
		"date_action_filed": "2024-04-09",
		"current_jurisdiction": "C.D. Cal.",
		"jurisdiction_name": "California (federal)",
		"published_opinions_binary": -1,
		"status_disposition": "Active",
		"date_added": "2026-02-04",
		"last_update": "2026-02-04",
		"researcher": "Aiymgul Kachyke",
		"summary_of_significance": "This case illustrates the legal risks of using proprietary third-party data to benchmark Generative AI models. The court granted a preliminary injunction against an AI developer that 'screen-captured' copyrighted exam questions to test how well AI chatbots could answer them, rejecting the defense that the issue was moot because the files had been deleted.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "Order Granting Plaintiff's Motion for Preliminary Injunction.",
		"most_recent_activity_date": "2024-07-23",
		"keyword": "International Council for Veterinary Assessment v. Anivive Lifesciences Inc. The International Council for Veterinary Assessment sues Anivive Lifesciences Inc., asserting claims of copyright infringement and breach of contract arising from the defendants' alleged inputting of copyrighted veterinary licensing exam questions into AI chatbots to test the AI's performance. This case illustrates the legal risks of using proprietary third-party data to benchmark Generative AI models. The court granted a preliminary injunction against an AI developer that 'screen-captured' copyrighted exam questions to test how well AI chatbots could answer them, rejecting the defense that the issue was moot because the files had been deleted. ICVA filed suit alleging that Anivive Lifesciences and its executives infringed copyright by inputting questions from the North American Veterinary Licensing Examination (NAVLE) into 'three different AI chatbots' to write an academic article on AI performance. ICVA alleged that Defendant Bruyette accessed the web-based 'Self-Assessment Form 2,' which prohibits copying, and took screenshots of the questions to distribute to his co-authors. Defendants argued the request for an injunction was moot because they had deleted the files, but the court rejected this, noting the lack of clear evidence of cessation. International Council for Veterinary Assessment; Anivive Lifesciences Inc.; David Bruyette; Cody Arbuckle; Dylan Balsz; Dorsey and Whitney LLP; Latham and Watkins LLP AI Chatbots; Large Language Models E-Learning, Generative AI, Intellectual Property, Licensing Agreement Breach of Contract, Copyright Infringement California (federal) Misuse of AI, Terms of Service, Copyright Infringement, Fair Use",
		"jurisdiction_type_text": "U.S. Federal",
		"filing_year": 2024,
		"case_id": "5b81bc866dd359d2a33239e749d3784a"
	},
	{
		"case_snug": "berliner-v-nassau-county",
		"id": 4,
		"record_number": 4,
		"caption": "Berliner v. Nassau County",
		"brief_description": "Nassau residents brought a class action against the county for an inaccurate and incomplete property tax reassessment algorithm as unfair and unconstitutional, granted a preliminary injunction against the county using this reassessment for 2020 real property taxes, almost settling but for the question of legal fees",
		"area_of_application_list": "'Constitutional Law','Real Property','Tax'",
		"area_of_application_text": "Real Property; Tax",
		"issue_text": "42 USC 1983, Equal Protection, Due Process, Preliminary Injunction,Underperformance,  Transparency in Change of Algorithm, Notice, Lack of Remedy",
		"issue_list": "'42 USC 1983','Due Process','Equal Protection','Lack of Remedy','Notice','Underperformance','Preliminary Injunction','Transparency in Change of Algorithm'",
		"cause_of_action_list": "'42 USC 1983','Due Process','Equal Protection','Preliminary Injunction'",
		"cause_of_action_text": "42 USC 1983; Equal Protection; Due Process; Preliminary Injunction",
		"issue_list_old": "'Lack of Human Review','Notice','Transparency in Change of Algorithm','Underperformance'",
		"issue_text_old": "Underperformance;  Transparency in Change of Algorithm; Notice; Lack of Remedy",
		"name_of_algorithm_list": "",
		"name_of_algorithm_text": "",
		"class_action_list": "",
		"organizations_involved": "",
		"jurisdiction_filed": "N.Y. Nassau County Ct.",
		"date_action_filed": "2019-04-30",
		"current_jurisdiction": "N.Y. Nassau County Ct.",
		"jurisdiction_name": "New York",
		"published_opinions_binary": -1,
		"status_disposition": "Inactive",
		"date_added": "2021-02-01",
		"last_update": "2022-05-01",
		"researcher": "Sydney",
		"summary_of_significance": "Berliner filed this class action to get disclosure of the county's property tax reassessment algorithm. The county discontinued its argument of trade secrecy and produced the algorithm, leading residents to challenge the legality because the algorithm had missing files that would not let the code run effectively. \nA New York lower court ruled that the class action of Nassau County residents can move forward, the ruling resulted in the discontinuation of the Reassessment algorithm in question and reverting to the previous market value and tax levels for the 2020 tax assessment. Plaintiffs allege that \"the reassessment was rushed, and conducted in an arbitrary, unscientific, and unfair manner lacking uniformity; that the reassessment failed to capture fair residential market values; that the use of neighborhood factoring produced striking discrepancies among similar properties; and was performed under a veil of secrecy with the utilization of undisclosed software and algorithms.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "Plaintiffs filed satisfaction of judgment",
		"most_recent_activity_date": "2021-03-08",
		"keyword": "Berliner v. Nassau County Nassau residents brought a class action against the county for an inaccurate and incomplete property tax reassessment algorithm as unfair and unconstitutional, granted a preliminary injunction against the county using this reassessment for 2020 real property taxes, almost settling but for the question of legal fees Berliner filed this class action to get disclosure of the county's property tax reassessment algorithm. The county discontinued its argument of trade secrecy and produced the algorithm, leading residents to challenge the legality because the algorithm had missing files that would not let the code run effectively. \nA New York lower court ruled that the class action of Nassau County residents can move forward, the ruling resulted in the discontinuation of the Reassessment algorithm in question and reverting to the previous market value and tax levels for the 2020 tax assessment. Plaintiffs allege that \"the reassessment was rushed, and conducted in an arbitrary, unscientific, and unfair manner lacking uniformity; that the reassessment failed to capture fair residential market values; that the use of neighborhood factoring produced striking discrepancies among similar properties; and was performed under a veil of secrecy with the utilization of undisclosed software and algorithms.\" In March 2018, Nassau County legislature approved reassessments of real property tax for the 2020-2021 tax season using. The algorithm used data of recent sales of comparable houses to produce a predictive model, then multiplying by a neighborhood factor of one of the 324 neighborhoods in the county to assess property value, with neighborhood factors ranging from .6 to 1.9. \n\nIn November 2018, the residents were notified of their preliminary market values that would roll out in April 2020, with 85,000 of the 400,000 houses needing reassessment before April 2020. The properties lowered in value did not have their tax accordingly lowered.\n\nIn the complaint filed in April 2019, the plaintiffs allege: the countywide reassessment was rushed, and conducted in an arbitrary, unscientific, and unfair manner lacking uniformity; that the reassessment failed to capture fair residential market values; that the use of neighborhood factoring produced striking discrepancies among similar properties; and was performed under a veil of secrecy with the utilization of undisclosed software and algorithms.\" The underassessed homes would see their taxes increase, and over assessed homes would challenge the valuation.\n\nDuring this time in summer of 2020, a second lawsuit by Sean M. McCarthy is dismissed with ID Number 607458 / 2020.\n\nJudgement on Plaintiff's October 1, 2020 motion for attorney's fees as part of the settlement agreement, ordered on December 1, corrected on December 22 and entered on December 28 awarding fees and costs of $300,000 to Plaintiffs.\n\nNassau County Appeals to the Appellate Division of the Supreme Court of the State of New York, did the court err in finding the plaintiffs had established entitlement to award?\n\nIn March 2021, plaintiffs filed certificate for satisfaction of judgment.\n\nIn April 2021, plaintiffs brought issue with Nassau County sending out fliers that stated \"ALERT NASSAU COUNTY DID NOT RAISE TAXES\" and other statements relating to the lawsuit.   Real Property; Tax 42 USC 1983; Equal Protection; Due Process; Preliminary Injunction New York Underperformance;  Transparency in Change of Algorithm; Notice; Lack of Remedy",
		"jurisdiction_type_text": "U.S. State",
		"filing_year": 2019,
		"case_id": "fa921fc31e1a8d2fc96f01a6c2046786"
	},
	{
		"case_snug": "",
		"id": 374,
		"record_number": 374,
		"caption": "In Re Mosaic LLM Litigation",
		"brief_description": "Book authors file a class action against a generative AI developer and its acquired company, asserting claims of Copyright Infringement, arising from the defendants' alleged copying of authors' works to train their MPT and DBRX series Large Language Models.",
		"area_of_application_list": "'Copyright','Generative AI','Intellectual Property'",
		"area_of_application_text": "Copyright, Generative AI, Intellectual Property",
		"issue_text": "17 U.S.C. 1202 Removal of Copyright Management Information,Infringement, Copyright Infringement, Fair Use",
		"issue_list": "'17 U.S.C. 1202 Removal of Copyright Management Information','Copyright Infringement','Fair Use','Infringement'",
		"cause_of_action_list": "'17 U.S.C. 1202 Removal of Copyright Management Information'",
		"cause_of_action_text": "17 U.S.C. 1202 Removal of Copyright Management Information",
		"issue_list_old": "'Infringement','Copyright Infringement','Fair Use'",
		"issue_text_old": "Infringement, Copyright Infringement, Fair Use",
		"name_of_algorithm_list": "",
		"name_of_algorithm_text": "MPT-7B; MPT-30B; DBRX",
		"class_action_list": "'Yes'",
		"organizations_involved": "Databricks, Inc.; MosaicML, Inc.; Rebecca Makkai; Jason Reynolds; Stewart O'Nan; Brian Keene; Abdi Nazemian",
		"jurisdiction_filed": "N.D. Cal.",
		"date_action_filed": "2024-03-08",
		"current_jurisdiction": "N.D. Cal.",
		"jurisdiction_name": "California (federal)",
		"published_opinions_binary": -1,
		"status_disposition": "Active",
		"date_added": "2025-12-11",
		"last_update": "2026-01-17",
		"researcher": "Aiymgul Kachyke",
		"summary_of_significance": "This is a major test case for copyright law against generative AI developers, focusing on the copying of creative works to train Large Language Models (LLMs). It is significant because it directly challenges the training data acquisition methods of foundational models like the MPT series and DBRX. The case is being closely watched for its implications on the fair use defense in the context of commercial AI development.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "Parties filed a Joint Stipulation and Proposed Order to modify the scheduling order to allow for leave to file a Second Amended Consolidated Complaint",
		"most_recent_activity_date": "2025-11-20",
		"keyword": "In Re Mosaic LLM Litigation Book authors file a class action against a generative AI developer and its acquired company, asserting claims of Copyright Infringement, arising from the defendants' alleged copying of authors' works to train their MPT and DBRX series Large Language Models. This is a major test case for copyright law against generative AI developers, focusing on the copying of creative works to train Large Language Models (LLMs). It is significant because it directly challenges the training data acquisition methods of foundational models like the MPT series and DBRX. The case is being closely watched for its implications on the fair use defense in the context of commercial AI development. The initial lawsuit was filed on March 8, 2024, by book authors against Databricks and its subsidiary MosaicML, alleging direct copyright infringement for using their works to train the MPT series LLMs. The case was later consolidated with a similar action and re-titled In Re Mosaic LLM Litigation. Plaintiffs later amended the complaint to add a direct infringement claim related to Databricks' new DBRX model. The court granted the defendants' motion to dismiss the DBRX-related infringement claim in August 2025, finding the allegations too generalized. The case is currently in the discovery phase, with disputes over the scope of discovery related to DBRX and deposition limits. Databricks, Inc.; MosaicML, Inc.; Rebecca Makkai; Jason Reynolds; Stewart O'Nan; Brian Keene; Abdi Nazemian MPT-7B; MPT-30B; DBRX Copyright, Generative AI, Intellectual Property 17 U.S.C. 1202 Removal of Copyright Management Information California (federal) Infringement, Copyright Infringement, Fair Use",
		"jurisdiction_type_text": "U.S. Federal",
		"filing_year": 2024,
		"case_id": "110ee5cf1b9167befdb9a038341c7b11"
	},
	{
		"case_snug": "",
		"id": 384,
		"record_number": 384,
		"caption": "Aaron Gross, et al. v. Madison Square Garden Entertainment Corp.",
		"brief_description": "Concertgoers file a class action against an entertainment venue operator, asserting claims of N.Y.C. Biometric Identifier Information Protection Code violations, and others, arising from the defendant's use of facial recognition technology to identify and exclude attorneys from its venues.",
		"area_of_application_list": "'Facial Recognition','Privacy'",
		"area_of_application_text": "Facial Recognition, Privacy",
		"issue_text": "Right to Privacy, Unjust Enrichment,Facial Recognition, Privacy",
		"issue_list": "'Facial Recognition','Privacy','Right To Privacy','Unjust Enrichment'",
		"cause_of_action_list": "'Right to Privacy','Unjust Enrichment'",
		"cause_of_action_text": "Right to Privacy, Unjust Enrichment",
		"issue_list_old": "'Facial Recognition','Privacy'",
		"issue_text_old": "Facial Recognition, Privacy",
		"name_of_algorithm_list": "",
		"name_of_algorithm_text": "Facial Recognition Technology; Biometric Identification System",
		"class_action_list": "'Yes'",
		"organizations_involved": "Madison Square Garden Entertainment Corp. (n/k/a Sphere Entertainment Co.)",
		"jurisdiction_filed": "S.D.N.Y.",
		"date_action_filed": "2023-03-24",
		"current_jurisdiction": "S.D.N.Y.",
		"jurisdiction_name": "New York (federal)",
		"published_opinions_binary": -1,
		"status_disposition": "Inactive",
		"date_added": "2025-12-19",
		"last_update": "2025-12-19",
		"researcher": "Aiymgul Kachyke",
		"summary_of_significance": "This case provides a critical interpretation of New York City's Biometric Identifier Information Protection Code, specifically the 'profiting' clause. The court ruled that using facial recognition to reduce litigation expenses by excluding adverse attorneys does not constitute 'profiting from a transaction' of biometric data under the statute's plain meaning.",
		"summary_facts_activity_to_date": "",
		"most_recent_activity": "Entry of Judgment dismissing the case in all respects.",
		"most_recent_activity_date": "2024-05-08",
		"keyword": "Aaron Gross, et al. v. Madison Square Garden Entertainment Corp. Concertgoers file a class action against an entertainment venue operator, asserting claims of N.Y.C. Biometric Identifier Information Protection Code violations, and others, arising from the defendant's use of facial recognition technology to identify and exclude attorneys from its venues. This case provides a critical interpretation of New York City's Biometric Identifier Information Protection Code, specifically the 'profiting' clause. The court ruled that using facial recognition to reduce litigation expenses by excluding adverse attorneys does not constitute 'profiting from a transaction' of biometric data under the statute's plain meaning. Plaintiffs Aaron Gross and Jacob Blumenkrantz sued MSG Entertainment, alleging the venue used facial recognition to identify and eject lawyers from firms engaged in litigation against MSG. They claimed this practice violated N.Y.C. law by 'profiting' from consumer biometric data through reduced litigation costs. MSG moved to dismiss, arguing it did not sell or trade the data for value. A Magistrate Judge initially recommended allowing the claim to proceed, finding that cost savings could potentially constitute 'profit'. However, U.S. District Judge Lewis Kaplan rejected this recommendation, ruling that 'profit' requires a more direct exchange of data for compensation than what was alleged. The court dismissed the complaint for failure to state a claim, and the case was closed in May 2024. Madison Square Garden Entertainment Corp. (n/k/a Sphere Entertainment Co.) Facial Recognition Technology; Biometric Identification System Facial Recognition, Privacy Right to Privacy, Unjust Enrichment New York (federal) Facial Recognition, Privacy",
		"jurisdiction_type_text": "U.S. Federal",
		"filing_year": 2023,
		"case_id": "e53e12228504645e5fb8d16df1cdff40"
	}
]
